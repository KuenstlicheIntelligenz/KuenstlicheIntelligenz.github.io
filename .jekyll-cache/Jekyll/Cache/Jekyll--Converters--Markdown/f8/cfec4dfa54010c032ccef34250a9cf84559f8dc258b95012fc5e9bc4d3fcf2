I"=<p><strong>Work in progress</strong></p>

<h1 id="why-dont-we-use-mean-and-max-pooling">Why don’t we use Mean and Max Pooling?</h1>
<p>IDEA: Probably cause the feature vector would be to long. -&gt; GeM
But what about using both and doing an autoencoder on it, the network could select and weight each
feature on its own.
Hybrid Pooling:
https://arxiv.org/pdf/1509.06033.pdf
-&gt; Concat Mean and Max pooling performes worse then just mean. But still the idea with the autoencoder hangs in the air</p>

<h1 id="why-do-we-use-2d-3x3-convolutional-filter-on-the-first-3-rgb-channels">Why do we use 2d 3x3 convolutional filter on the first 3 rgb channels?</h1>

<h1 id="why-dont-we-have-color-invariant-features-or-have-to-learn-them">Why don’t we have color invariant features, or have to learn them?</h1>
<p>Has humans we can recognize a wasp in a picture, no matter in what colors it is shown.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Wasps</th>
      <th style="text-align: center">Wasps</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/images/wasp.jpg" alt="wasp.jpg" /></td>
      <td style="text-align: center"><img src="/assets/images/wasp_inv.jpg" alt="wasp_inv.jpg" /></td>
    </tr>
    <tr>
      <td style="text-align: center">Fir0002/Flagstaffotos</td>
      <td style="text-align: center">Fir0002/Flagstaffotos</td>
    </tr>
  </tbody>
</table>

<h1 id="cnn-is-not-rotation-invariant-how-to-deal-with-it">CNN is not rotation invariant, how to deal with it?</h1>
<p>Train it with slight rotation, then get features for 0, 90, 180, 270 degrees</p>

<h1 id="can-we-somhow-penalize-sparsity-in-dnns">Can we somhow penalize sparsity in DNNs?</h1>

<h1 id="train-using-contrastive-loss-or-categorical-loss">Train using contrastive loss or categorical loss?</h1>

:ET